---
title: "Week 3 seminar"
author:
  - Prof. Joshua Loftus (lecturer)
  - Shakeel GAvioli-Akilagun (GTA)
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(broom)
```

## Categorical outcome data

We will use the `attrition` data set. This is a synthetic data set created by IBM data scientists in the 1970s for uncovering "he factors that lead to employee attrition". The data set lives in the `modeldata` package. Load the data and have a look at the first few rows: 

```{r}
library(modeldata)
```

At the end of the seminar we will fit a model to describe the attrition rate of IMB employees. Compare visually the distribution of a numeric predictor variable between the two outcome classes

```{r}

```

Perform a two sample t-test for a difference in means. In base R this can be done using the `t.test` function. What is the outcome of your test at the 95% confidence level? 

```{r}

```

Look at the `Attrition` variable, are the classes balanced? 

```{r}

```

Create a balanced data set with the same number of observations in both classes

```{r}

```


## Classification: linear regression?

Can we do classification with a simple linear regression? Create a new data set consisting of your numeric predictor and the response varaible transformed to be numeric:


```{r}

```

Fit a simple linear regression to this dataset. Plot the fitted line however you see fit. Does the relationship your model implies make sense?

```{r}

```

Ok, now lets use the regression model for classification. We cand do this with a simple threshold rule: 

$$
\hat{z}_i = \begin{cases}
0 &  \hat{\alpha} + \hat{\beta} x_i < c \\ 
1 & \text{ else } 
\end{cases}
$$

Plot linear regression line, change the threshold

```{r}

```

Note, an alternative to fixing the class imbalance problem is to simply adjust the threshold. Let's see how that would work by fitting the same regression to the full dataset. 

```{r}

```

Why might it not be a good idea to use a linear regression for this task? 
  * Our model can predict outside 0-1 range
  * Not directly interpretable as probabilities

### Thresholding ideas

Choose a threshold/cutoff value for predictor $X$, say $c$, and then classify

- $\hat Y = 1$ if $X \geq c$
- $\hat Y = 0$ otherwise

Or if the association is negative, change the sign

As we vary $c$, we trade-off between kinds of errors: false positives and false negatives

In the simple case with thresholding one predictor, the classification/decision rules are all equivalent whether we use linear regression or logistic regression (as long as the fitted relationship is monotone)

For **multiple** regression--when we have more predictors--we can then transform a numeric prediction from the model $\hat Y$ to a classification by using a threshold rule on the scale of the predictions (instead of on the scale of one predictor as before)

- $\hat Y = 1$ if $x^T \hat \beta \geq c$
- $\hat Y = 0$ otherwise

## Logistic regression

The main idea is to model conditional probabilities using the **logistic function**: 

$$
P(Y = 1 \mid X = x ) = \frac{\exp(\beta_0 + \beta_1 x)}{1 + \exp(\beta_0 + \beta_1 x)}
$$

Alternatively, we may write:

$$
\text{logistic}[P(Y=1 \mid X = x )] = \beta_0 + \beta_1 x
$$

Fit a logistic regression to the same variables you used in the previous section. Plot the results and comment on any differences: 

```{r}

```

Call the `summary` function on your model. What are the similarities and differences as compared to what you would expect to see from an `lm` object? 

```{r}

```

### Interpreting coefficients

The linear component of the logistic regression is interpretable as a "log-odds" ratio. That is, writing $p(x) = P (Y = 1 \mid X = x)$ we have: 

$$
\log \left ( \frac{p(x)}{1-p(x)} \right ) = \beta_0 + \beta_1 x 
$$

Exponentiation coefficients gives an interpretation in terms of the multiplicative change in the odds of belonging to one of the two classes. Have a go interpreting your model:  

```{r}

```


## Balance and (re)calibration

What portion of data are classified using a given cutoff for the predicted probability?

```{r}

```

Write a function to tabulate a confusion matrix (using dplyr functions)

```{r}
get_confusion_matrix <- function(fitted_glm, cutoff = .5) 
  {
  #' Get confusion matrix from fitted glm
  #'
  #'@param fitted_glm
  #'@param cutoff 
  

}
```

Apply your function to the estimated glm we have been using throughout the notebook. 

```{r}

```


## Simulation

Write a function like `y = f(x) + noise` to generate data (with sample size as an input to the function)

Start with a linear function and Gaussian noise

```{r}
gg <- function(x) 1 - 2*x

simulate_df_one_pred <- function(nn, ff)
{
  #' Simulates from the model `y = f(x) + noise`
  #'
  #'@param nn int, the sample size
  #'@param ff function of one argment which returns a float
  

}
```

Simulate one dataset with a sample size of 20, fit a linear regression model, and extract the slope estimate

```{r}

```

Repeat this 100 times using `replicate()`, plot a histogram of the coefficient estimates, add a `geom_vline` at the true coefficient value. Increase the sample size and try again

```{r}

```


### Complexity the above

(Complete outside of class time unless time permits)

Now try making `hh` a function of two variables, where `x1` and `x2` are both (possibly noisey) functions of a hidden variable `uu`. 

What are the true coefficients? How do we interpret them? What happens if we regress on only `x1` or only `x2`? What would be the change in outcome if we could intervene on `x1` (erasing the influence of `uu` on `x1` but keeping it for `x2`)? What if we could intervene on `uu`?

```{r}

hh <- function(x1, x2) 5 + 2 * x1 - 7 * x2

simulate_df_two_pred <- function(nn, ff) 
{
  #' Simulates from the model `y = f(x1, x2) + noise`
  #'
  #'@param nn int, the sample size
  #'@param ff function of two argments which returns a float
  
}
```

```{r}

```


If we regress on only one at a time the estimates can be biased (omitted variable bias)

If we could intervene on `x1` directly then `beta1` (the true value, not the estimate) would tell us the causal effect on the outcome

If we could intervene on `u` then the total effect on `y` would involve both `beta1` and `beta2`, as well as the coefficients of `u` on both `x1` and `x2`

e.g. increasing `u` by 1 would make `x1` increase by 3 and `x2` decrease by 7, hence `y` would change by `3*beta - 7*beta2`

# Extra practice

(Complete outside of class time unless time permits)

* Repeat the previous simulations but generate a binary outcome and use logistic regression to estimate coefficients

* Repeat your analysis of the `attrition` dataset using (i) a multiple linear regression and (ii) a multiple logistic regression. 

